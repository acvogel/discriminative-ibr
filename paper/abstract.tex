Recursive Bayesian models of linguistic communication capture a
variety of intricate kinds of pragmatic enrichment, but they tend to
depend on the unrealistic assumption that agents are invariably
optimal reasoners. We present a discriminative model that seeks to
capitalize on the insights of such approaches while addressing these
concerns about inferential power. The model relies on only approximate
representations of language and context, and its recursive properties
are limited to the training phase. The resulting behavior is often not
optimal, but we present experimental evidence that this suboptimal
behavior is closely aligned with human performance on both simple and
complex reference games.
